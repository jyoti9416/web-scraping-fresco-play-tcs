import bs4
from bs4 import BeautifulSoup
import csv
import requests
import time
import pandas as pd
import urllib
import re
import pickle

#### Start you code here, you are free to add any number of cells
columns_names = ['date','Average temperature (°F)', 'Average humidity (%)',
 'Average dewpoint (°F)', 'Average barometer (in)',
 'Average windspeed (mph)', 'Average gustspeed (mph)',
 'Average direction (°deg)', 'Rainfall for month (in)',
 'Rainfall for year (in)', 'Maximum rain per minute',
 'Maximum temperature (°F)', 'Minimum temperature (°F)',
 'Maximum humidity (%)', 'Minimum humidity (%)', 'Maximum pressure',
 'Minimum pressure', 'Maximum windspeed (mph)',
 'Maximum gust speed (mph)', 'Maximum heat index (°F)'
 
start_date = '2009-01-01'
end_date = '2018-10-28'

dates_list = pd.date_range(start=start_date,end=end_date,freq='M')
dates = [i.strftime('%Y%m') for i in dates_list]

data = []
for i in range(len(dates)):
    url = "http://www.estesparkweather.net/archive_reports.php?date="+dates[i]
    page = requests.get(URL)
    soup = BeautifulSoup(page.content,"html.parser")
    table = soup.find_all('table')
    raw_data = [row.text.splitlines() for row in table]
    raw_data = raw_data[:-9]
    year = dates[i][:4]
    for i in range(len(raw_data)):
        raw_data[i] = raw_data[i][2::3]
    for day in raw_data:
        index_dt = datetime.datetime.strptime(day[0][:5]+' '+year,'%b %m %Y')
        index_str = index_dt.strftime('%Y-%m-%d')
        Average_temperature = re.search('[0-9]+\.[0-9]+',day[1]).group()
        Average_humidity = re.search('[0-9]+',day[2]).group()
        Average_dewpoint = re.search('[0-9]+\.[0-9]+',day[3]).group()
        Average_barometer = re.search('[0-9]+\.[0-9]+',day[4]).group()
        Average_windspeed = re.search('[0-9]+\.[0-9]+',day[5]).group()
        Average_gustspeed = re.search('[0-9]+\.[0-9]+',day[6]).group()
        Average_direction = re.search('[0-9]+',day[7]).group()
        rainfall_month = re.search('[0-9]+\.[0-9]+',day[8]).group()
        rainfall_year = re.search('[0-9]+\.[0-9]+',day[9]).group()
        max_rain_per_min = re.search('[0-9]+\.[0-9]+',day[10]).group()
        Maximum_temperature = re.search('[0-9]+\.[0-9]+',day[11]).group()
        Minimum_temperature = re.search('[0-9]+\.[0-9]+',day[12]).group()
        Maximum_humidity = re.search('[0-9]+',day[13]).group()
        Minimum_humidity = re.search('[0-9]+',day[14]).group()
        Maximum_pressure  = re.search('[0-9]+\.[0-9]+',day[15]).group()
        Minimum_pressure = re.search('[0-9]+\.[0-9]+',day[16]).group()
        Maximum_windspeed = re.search('[0-9]+\.[0-9]+',day[17]).group()
        Maximum_gust_speed = re.search('[0-9]+',day[18]).group()
        Maximum_heat_index = re.search('[0-9]+',day[19]).group()
        data.append([index_str,Average_temperature,Average_humidity,Average_dewpoint,Average_barometer,Average_windspeed,Average_gustspeed,
                    Average_direction,rainfall_month,rainfall_year,max_rain_per_min,Maximum_temperature,Minimum_temperature,
                    Maximum_humidity,Minimum_humidity,Maximum_pressure,Minimum_pressure,Maximum_windspeed,Maximum_gust_speed,Maximum_heat_index])       
                    
df = pd.DataFrame(data=data,columns=columns_names)
df.head()

df['date'] = pd.to_datetime(df['date'], format="%Y-%m-%d")

df1 = df.copy()
df1.set_index('date',inplace=True)

for col in df1.columns:
    df1[col] = df1[col].astype('float')
    
with open("dataframe.pk", "wb") as file:
    pickle.dump(df1, file)    
